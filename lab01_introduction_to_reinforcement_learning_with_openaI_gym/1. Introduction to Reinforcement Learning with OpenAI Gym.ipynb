{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1. Introduction to Reinforcement Learning with OpenAI Gym-checkpoint.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd6GdUs0j8lq",
        "colab_type": "text"
      },
      "source": [
        "## 강화학습(Reinforcement Learning)이란?\n",
        "위키피디아에 따르면 강화학습의 정의는 다음과 같다.\n",
        ">어떤 환경 안에서 정의된 에이전트가 현재의 상태를 인식하여, 선택 가능한 행동 중 보상을 최대화하는 행동 혹은 행동 순서를 선택하는 방법\n",
        "\n",
        "강화학습은 **정답이나 잘못된 선택에 대한 정정이 주어지지 않는** 특징이 있다. 그렇기에 MDP(Markov Decision Process)를 정의해 강화학습 문제를 푼다.\n",
        "\n",
        "### 예시\n",
        "- [AlphaGo](https://deepmind.com/research/case-studies/alphago-the-story-so-far)\n",
        "- [AlphaStar](https://deepmind.com/research/publications/AlphaStar-Grandmaster-level-in-StarCraft-II-using-multi-agent-reinforcement-learning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra-aUqUsswrk",
        "colab_type": "text"
      },
      "source": [
        "## MDP(Markov Decision Process)\n",
        "강화학습 문제를 풀 땐 MDP를 잘 정의하는 게 우선이다. MDP는 다음 구성요소를 가진다.\n",
        "- 상태 (State)\n",
        "- 행동 (Action)\n",
        "- 보상 (Reward)\n",
        "- 상태 변환 확률 (State Transition Probability)\n",
        "- 감가율 (Discount Factor)\n",
        "\n",
        "이제 MDP의 각 요소가 무엇인지 알아보자.\n",
        "\n",
        "### 상태 (State)\n",
        "현재 에이전트의 정보이다. 이때 정보는 에이전트가 얻을 수 있는 것의 집합이다.\n",
        "\n",
        "바둑에선 바둑판이 state가 될 수 있고, 스타크래프트에선 미니맵이나 화면 등이 state가 될 수 있다.\n",
        "\n",
        "### 행동 (Action)\n",
        "에이전트가 어떤 상태에서 할 수 있는 행동의 집합이다.\n",
        "\n",
        "바둑에선 돌을 놓을 수 있는 위치의 집합이 action이 될 수 있다.\n",
        "\n",
        "### 보상 (Reward)\n",
        "에이전트가 학습하는데 참고할 수 있는 **유일한** 정보다. 에이전트는 보상을 많이 받는 방향으로 학습해야 한다.\n",
        "\n",
        "이겼으면 1점, 졌으면 -1점. 혹은 여러 복잡한 방식으로 보상을 정의할 수 있다.\n",
        "\n",
        "### 상태 변환 확률 (State Transition Probability)\n",
        "어떤 상태에서 다른 상태로 변하지 못할 수도 있다. 예컨대 미로찾기에서 벽을 뚫을 순 없다. 또한, A에서 B로 변환될 확률보다 A에서 C로 변환될 확률이 높을 수도 있다.\n",
        "이처럼 상태의 변화엔 확률적인 요인이 들어가는데, 이를 수치적으로 표현한 것이 상태 변환 확률이다.\n",
        "\n",
        "### 감가율 (Discount Factor)\n",
        "같은 양의 보상이면 먼 미래에 받는 것보단 바로 받는 게 이득이다. 이를 수학적으로 표현한 것이다.\n",
        "\n",
        "가령 감가율을 0.9라 하자. 지금 바로 100의 보상을 받는다면 100이지만, 감가율을 적용한다면 2턴 후에 주어지는 100의 보상은 0.9 × 0.9 × 100 = 81로 가치가 줄어든다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK-M4eB9TP5f",
        "colab_type": "text"
      },
      "source": [
        "## OpenAI Gym\n",
        "강화학습엔 환경(environment)이 필요하다. OpenAI Gym는  다양한 강화학습 환경을 제공한다.\n",
        "\n",
        "이제 OpenAI Gym을 설치해 본격적으로 강화학습을 실습해보자.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMevRkF7YwuC",
        "colab_type": "code",
        "outputId": "6a39a620-c88c-4ab0-ac57-f06cdfdc3cb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "# 필요한 패키지를 설치해준다.\n",
        "!cat requirements.txt\n",
        "!echo '----------------------------------'\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gym\r\n",
            "numpy\r\n",
            "matplotlib\r\n",
            "----------------------------------\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.15.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.17.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from gym->-r requirements.txt (line 1)) (4.1.2.30)\n",
            "Requirement already satisfied: cloudpickle~=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->-r requirements.txt (line 1)) (1.2.2)\n",
            "Requirement already satisfied: pyglet<=1.3.2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->-r requirements.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 3)) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 3)) (2.4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->-r requirements.txt (line 3)) (42.0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NImuLvpYa2y6",
        "colab_type": "text"
      },
      "source": [
        "## Frozen Lake\n",
        "처음으로 실습할 환경은 ***Frozen Lake***다. Frozen Lake는 에이전트가 구멍을 피해 얼어있는 강을 건너는 환경이다.\n",
        "\n",
        "판의 크기는 4 by 4로 총 16칸이며, 에이전트는 상하좌우로 한 칸 이동할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z93Sx8FnY9hc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 다음 코드를 통해 FrozenLake 환경을 불러올 수 있다.\n",
        "import gym\n",
        "\n",
        "env = gym.make(\"FrozenLake-v0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mprDLfVaEkX",
        "colab_type": "code",
        "outputId": "5fe7df14-d705-4662-f381-927f49f74473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "# 환경에 관한 정보는 다음과 같이 얻을 수 있다.\n",
        "\n",
        "print('Observation Space:', env.observation_space)\n",
        "print('Observation Space Size:', env.observation_space.n)\n",
        "print('Action Space:', env.action_space)\n",
        "print('Action Space Size:', env.action_space.n)\n",
        "\n",
        "env.render()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation Space: Discrete(16)\n",
            "Observation Space Size: 16\n",
            "Action Space: Discrete(4)\n",
            "Action Space Size: 4\n",
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfBlEi2P3mBC",
        "colab_type": "code",
        "outputId": "6feb3e8b-2c5f-4c50-a24f-91f012740f6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# episode를 시작하기 전엔 reset 메소드를 호출해야한다.\n",
        "# reset 메소드는 state를 반환한다.\n",
        "state = env.reset()\n",
        "print(state)\n",
        "\n",
        "# step 메소드를 이용해 한 스텝 진행할 수 있다.\n",
        "# step 메소드는 새로운 state, 보상, 끝났는지 여부, 기타 정보를 반환한다.\n",
        "next_state, reward, done, _ = env.step(env.action_space.sample())\n",
        "print('next_state:', next_state)\n",
        "print('reward:', reward)\n",
        "print('done:', done)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "next_state: 1\n",
            "reward: 0.0\n",
            "done: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue4hyl09awtI",
        "colab_type": "code",
        "outputId": "813e31c6-c641-4570-ae33-265cb3aa2e32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 지금까지 배운 내용으로 무작위로 행동하는 에이전트를 만들어보자.\n",
        "\n",
        "# 환경을 만든다\n",
        "env = gym.make('FrozenLake-v0')\n",
        "\n",
        "# Episode를 시작하기 전엔 반드시 reset 메소드를 호출해야한다.\n",
        "state = env.reset()\n",
        "\n",
        "while True:\n",
        "  # 환경을 출력한다.\n",
        "  env.render()\n",
        "\n",
        "  # Action space에서 무작위 행동을 가져온다.\n",
        "  action = env.action_space.sample()\n",
        "\n",
        "  # 생성한 action을 바탕으로 한 스텝 진행한다.\n",
        "  new_state, reward, done, _ = env.step(action)\n",
        "\n",
        "  # Episode가 끝났다면 반복문을 빠져나간다.\n",
        "  if done:\n",
        "    print(reward)\n",
        "    break\n",
        "\n",
        "  # state에 새로운 state를 할당한다. (지금은 의미 없음)\n",
        "  state = new_state\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Up)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "F\u001b[41mF\u001b[0mFH\n",
            "HFFG\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "  (Up)\n",
            "SFFF\n",
            "FHFH\n",
            "F\u001b[41mF\u001b[0mFH\n",
            "HFFG\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Up)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Right)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Up)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Down)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Down)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Right)\n",
            "SF\u001b[41mF\u001b[0mF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Down)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Up)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Right)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Up)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej_d2Fi93w8X",
        "colab_type": "text"
      },
      "source": [
        "## Q Learning\n",
        "어떤 상황 *s*에서 어떤 행동 *a*의 가치를 Q(s, a)라 하자. 그렇다면 가장 좋은 행동은 Q(s, a)가 가장 큰 *a*이다.\n",
        "\n",
        "그렇다면 Q 값은 어떻게 구할까? 보상(reward)를 바탕으로 Q 값을 갱신하면 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ80OBbzCNcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# 최대인 값의 위치를 구하는 함수\n",
        "def arg_max(values):\n",
        "  max_index = [0]\n",
        "  max_value = values[0]\n",
        "\n",
        "  for index, value in enumerate(values[1:], 1):\n",
        "    if value > max_value:\n",
        "      max_index.clear()\n",
        "\n",
        "      max_value = value\n",
        "      max_index.append(index)\n",
        "    elif value == max_value:\n",
        "      max_index.append(index)\n",
        "\n",
        "    return random.choice(max_index)\n",
        "\n",
        "# Q-Learning를 이용한 에이전트를 만들자.\n",
        "class Agent:\n",
        "  def __init__(self, actions):\n",
        "    # 할 수 있는 행동의 집합\n",
        "    self.actions = actions\n",
        "\n",
        "    # 학습률로, 한 번에 얼마나 학습할지 결정한다.\n",
        "    self.learning_rate = 1e-2\n",
        "\n",
        "    # 감가율\n",
        "    self.discount_factor = 0.9\n",
        "\n",
        "    # 무작위로 행동을 선택할 비율이다.\n",
        "    # 강화학습에선 탐험이 중요하기 때문에 무작위 선택도 넣는다.\n",
        "    self.epsilon = 0.9\n",
        "\n",
        "    # Q(s, a)를 담아둔 테이블이다\n",
        "    self.q_table = defaultdict(lambda: [0. for _ in range(actions.n)])\n",
        "\n",
        "  # state를 받아 할 행동을 구하는 메소드\n",
        "  def get_action(self, state):\n",
        "    if random.random() < self.epsilon:\n",
        "      # 일정한 확률로 임의의 행동을 한다.\n",
        "      return self.actions.sample()\n",
        "    else:\n",
        "      q_values = self.q_table[state]\n",
        "      return arg_max(q_values)\n",
        "\n",
        "  # 보상을 바탕으로 Q table을 업데이트 하는 메소드\n",
        "  def train(self, state, action, reward, next_state):\n",
        "    q1 = self.q_table[state][action]\n",
        "    q2 = reward + self.discount_factor * max(self.q_table[next_state])\n",
        "\n",
        "    self.q_table[state][action] += self.learning_rate * (q2 - q1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4etWGID7vA2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 위에서 만든 에이전트를 바탕으로 학습을 시켜보자.\n",
        "env = gym.make('FrozenLake-v0')\n",
        "agent = Agent(env.action_space)\n",
        "\n",
        "# 시간에 따른 보상의 변화를 보기 위해 받은 보상을 저장해두자.\n",
        "rewards = []\n",
        "\n",
        "# 1000 에피소드를 수행한다.\n",
        "for episode in range(1, 10000 + 1):\n",
        "  state = env.reset()\n",
        "\n",
        "  episode_rewards = []\n",
        "  while True:\n",
        "    action = agent.get_action(state)\n",
        "    next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "    agent.train(state, action, reward, next_state)\n",
        "    state = next_state\n",
        "\n",
        "    episode_rewards.append(reward)\n",
        "\n",
        "    if done:\n",
        "      break\n",
        "\n",
        "  rewards.append(sum(episode_rewards) / len(episode_rewards))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkwhUb8ZxboH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "dc7908a6-ed90-4fdb-beae-b0b810681f01"
      },
      "source": [
        "# 이제 그래프를 그려보자\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "X = [i for i in range(1, 10000 + 1)]\n",
        "\n",
        "plt.plot(X, rewards)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Reward')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEKCAYAAADq59mMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDMOIjCkPwzAMIzL/Hz+2+ROKBDy7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU5-f7rrxtSU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "8fd74fe2-c24c-4519-fb5d-04a82acf6bad"
      },
      "source": [
        "# 에이전트가 정상적으로 학습이 됐는지 확인하기 위해 epsilon을 0으로 하고 에피소드를 수행해보자.\n",
        "state = env.reset()\n",
        "agent.epsilon = 0\n",
        "\n",
        "while True:\n",
        "  env.render()\n",
        "\n",
        "  action = agent.get_action(state)\n",
        "  next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "  agent.train(state, action, reward, next_state)\n",
        "  state = next_state\n",
        "\n",
        "  if done:\n",
        "    break"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npa-6LfYyQxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}