{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1. OpenAI Gym.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK-M4eB9TP5f",
        "colab_type": "text"
      },
      "source": [
        "## OpenAI Gym\n",
        "강화학습엔 환경(environment)이 필요하다. OpenAI Gym는  다양한 강화학습 환경을 제공한다.\n",
        "\n",
        "이제 OpenAI Gym을 설치해 본격적으로 강화학습을 실습해보자.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-VP-I-Tmlus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./RL_2020\n",
        "!git clone https://github.com/HanyangTechAI/RL_2020.git\n",
        "!rm -rf ./RL_2020/.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMevRkF7YwuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 필요한 패키지를 설치해준다.\n",
        "!cat ./RL_2020/lab01_introduction_to_reinforcement_learning_with_openaI_gym/requirements.txt\n",
        "!echo '----------------------------------'\n",
        "!pip install -r ./RL_2020/lab01_introduction_to_reinforcement_learning_with_openaI_gym/requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NImuLvpYa2y6",
        "colab_type": "text"
      },
      "source": [
        "## Frozen Lake\n",
        "처음으로 실습할 환경은 ***Frozen Lake***다. Frozen Lake는 에이전트가 구멍을 피해 얼어있는 강을 건너는 환경이다.\n",
        "\n",
        "판의 크기는 4 by 4로 총 16칸이며, 에이전트는 상하좌우로 한 칸 이동할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z93Sx8FnY9hc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 다음 코드를 통해 FrozenLake 환경을 불러올 수 있다.\n",
        "import gym\n",
        "\n",
        "env = gym.make(\"FrozenLake-v0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mprDLfVaEkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 환경에 관한 정보는 다음과 같이 얻을 수 있다.\n",
        "\n",
        "print('Observation Space:', env.observation_space)\n",
        "print('Observation Space Size:', env.observation_space.n)\n",
        "print('Action Space:', env.action_space)\n",
        "print('Action Space Size:', env.action_space.n)\n",
        "\n",
        "env.render()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfBlEi2P3mBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# episode를 시작하기 전엔 reset 메소드를 호출해야한다.\n",
        "# reset 메소드는 state를 반환한다.\n",
        "state = env.reset()\n",
        "print(state)\n",
        "\n",
        "# step 메소드를 이용해 한 스텝 진행할 수 있다.\n",
        "# step 메소드는 새로운 state, 보상, 끝났는지 여부, 기타 정보를 반환한다.\n",
        "next_state, reward, done, _ = env.step(env.action_space.sample())\n",
        "print('next_state:', next_state)\n",
        "print('reward:', reward)\n",
        "print('done:', done)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue4hyl09awtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 지금까지 배운 내용으로 무작위로 행동하는 에이전트를 만들어보자.\n",
        "\n",
        "# 환경을 만든다\n",
        "env = gym.make('FrozenLake-v0')\n",
        "\n",
        "# Episode를 시작하기 전엔 반드시 reset 메소드를 호출해야한다.\n",
        "state = env.reset()\n",
        "\n",
        "while True:\n",
        "  # 환경을 출력한다.\n",
        "  env.render()\n",
        "\n",
        "  # Action space에서 무작위 행동을 가져온다.\n",
        "  action = env.action_space.sample()\n",
        "\n",
        "  # 생성한 action을 바탕으로 한 스텝 진행한다.\n",
        "  new_state, reward, done, _ = env.step(action)\n",
        "\n",
        "  # Episode가 끝났다면 반복문을 빠져나간다.\n",
        "  if done:\n",
        "    print(reward)\n",
        "    break\n",
        "\n",
        "  # state에 새로운 state를 할당한다.\n",
        "  state = new_state\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6NA1ReES0Lc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}